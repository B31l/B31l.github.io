---
title: "λ”¥λ¬λ‹ μ΄λ΅ : μμ „ν & μ—­μ „ν"
categories: [AI-λ”¥λ¬λ‹ μ΄λ΅ ]
mathjax: true
---

* content
{:toc}
# μ—ν¬ν¬

```python
for epoch in range(num_epochs):
    for x_batch, y_batch in train_dl:
        
        pred = model(x_batch)
        loss = loss_fn(pred, y_batch)
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()
```



## μμ „ν(Forward propagation)

μ‹ κ²½λ§μ **κ³„μΈµ**(Layer)μ„ κµ¬μ„±ν•λ” λ¨λ“  **λ…Έλ“**(Node)λ” κ°κ°μ **κ°€μ¤‘μΉ**(Weight)μ™€ **νΈν–¥**(bias)μ„ κ°€μ§€κ³  μλ‹¤.

μμ „ν(Forward propagation) κ³Όμ •μ—μ„λ” λ°μ΄ν„°**X**κ°€ μ…λ ¥λλ©΄ κ°€μ¤‘μΉ**W** λ° νΈν–¥**b**μ„ μ‚¬μ©ν•΄ μ…λ ¥μΈµμ—μ„ μ¶λ ¥μΈµ λ°©ν–¥μΌλ΅ μ΄λ™ν•λ©° μμΈ΅κ°’μ„ κ³„μ‚°ν•κ³ , μ†μ‹¤ ν•¨μλ¥Ό μ‚¬μ©ν•΄ μμΈ΅κ°’κ³Ό μ‹¤μ κ°’μ μ¤μ°¨**Loss**λ¥Ό κµ¬ν•λ‹¤.

```python
pred = model(x_batch)
loss = loss_fn(pred, y_batch)
```

## μ—­μ „ν(Back propagation)

μμ „ν κ³Όμ •μ—μ„ κµ¬ν• μ¤μ°¨λ¥Ό μµμ†ν™”ν•κΈ° μ„ν•΄ κ° λ…Έλ“μ κ°€μ¤‘μΉμ™€ νΈν–¥μ„ μμ •ν•΄μ•Ό ν•λ‹¤.

μ—­μ „ν(Back propagation) κ³Όμ •μ—μ„λ” μ—°μ‡„ λ²•μΉ™μ„ μ‚¬μ©ν•΄ μ¤μ°¨**Loss**λ¥Ό κ°€μ¤‘μΉ**W** λλ” νΈν–¥**b**μΌλ΅ νΈλ―Έλ¶„ν•λ‹¤.

```python
loss.backward()
optimizer.step()
```



## μλ™ λ―Έλ¶„



---

# π“REF

-   **Machine Learning with PyTorch and Scikit-Learn**

